{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "def find_dist_logs(base_dir):\n",
    "    dist_log = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(\"dist\") and file.endswith(\".log\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                dist_log.append(full_path)\n",
    "    return dist_log\n",
    "\n",
    "def keep_first_last_n_lines(filepath, n=10):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if len(lines) <= 2 * n:\n",
    "        # File is already short, keep all lines\n",
    "        return\n",
    "    # Get the first n and last n lines\n",
    "    new_lines = lines[:n] + lines[-n:]\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "base_dir = Path(\"~/Projects/chameleon/EXPS\").expanduser()\n",
    "for filepath in find_dist_logs(base_dir):\n",
    "    keep_first_last_n_lines(filepath, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f52c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, json, re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#from mpl_toolkits.axes_grid1 import host_subplot\n",
    "#import mpl_toolkits.axisartist as AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9e64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stats_json_files(base_dir):\n",
    "    \"\"\"Recursively find all system stats JSONL files under base_dir.\"\"\"\n",
    "    #base_dir = os.path.expanduser(base_dir)\n",
    "    stats_jsons = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(\"stats_\") and file.endswith(\".json\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                stats_jsons.append(full_path)\n",
    "    return stats_jsons\n",
    "\n",
    "def parse_path_fields(path):\n",
    "    parts = path.split(os.sep)\n",
    "    #print(f\"[DEBUG] parts: {parts}\")\n",
    "    filename = Path(path).name     # sys_stats_<port>_R<run>.jsonl\n",
    "    stem = Path(filename).stem     # sys_stats_<port>_R<run>\n",
    "    \n",
    "    run = None\n",
    "    for part in stem.split(\"_\"):\n",
    "        if part.startswith(\"R\") and part[1:].isdigit():\n",
    "            run = int(part[1:])\n",
    "            break\n",
    "\n",
    "    for i, p in enumerate(parts):\n",
    "        #if p in (\"mini-apps\", \"iperf\"):\n",
    "        if p in (\"iperf\", \"mini-apps\"):\n",
    "            return {\n",
    "                \"app\": p,\n",
    "                #\"date\": parts[i+1],\n",
    "                \"proxy\": parts[i+1],\n",
    "                \"congestion\": parts[i+2],\n",
    "                \"parallel\": parts[i+3],\n",
    "                \"duration\": parts[i+4],\n",
    "                \"run\": run\n",
    "            }\n",
    "    raise ValueError(f\"Path {path} does not match expected pattern.\")\n",
    "\n",
    "def load_all_stats(base_dir):\n",
    "    records = []\n",
    "    for filepath in find_stats_json_files(base_dir):\n",
    "        fields = parse_path_fields(filepath)\n",
    "        with open(filepath) as f:\n",
    "            first_line = f.readline()\n",
    "            try:\n",
    "                metadata = json.loads(first_line).get(\"metadata\", {})\n",
    "            except Exception as e:\n",
    "                print(f\"couldn't read the first line of {filepath}: {e}\")\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if \"timestamp\" not in rec:\n",
    "                    continue\n",
    "                row = {**fields, **rec, **metadata}\n",
    "                records.append(row)\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305a047",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     old_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m      7\u001b[0m     update_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([old_df, df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     update_df \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     update_df \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[0;32m~/Projects/chameleon/.chi/lib/python3.10/site-packages/pandas/core/frame.py:6818\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6815\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6816\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 6818\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   6819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   6820\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[0;32m~/Projects/chameleon/.chi/lib/python3.10/site-packages/pandas/core/frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[0;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Projects/chameleon/.chi/lib/python3.10/site-packages/pandas/core/frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[0;32m~/Projects/chameleon/.chi/lib/python3.10/site-packages/pandas/core/algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    803\u001b[0m         uniques,\n\u001b[1;32m    804\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    808\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/chameleon/.chi/lib/python3.10/site-packages/pandas/core/algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(\"~/Projects/chameleon/EXPS/cons\").expanduser()\n",
    "df = load_all_stats(BASE_DIR)\n",
    "csv_path = \"../data/cons.csv\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    if \"per_cpu\" in update_df.columns and update_df[\"per_cpu\"].apply(lambda x: isinstance(x, list)).any():\n",
    "        update_df[\"per_cpu\"] = update_df[\"per_cpu\"].apply(str)\n",
    "    old_df = pd.read_csv(csv_path)\n",
    "    update_df = pd.concat([old_df, df], ignore_index=True)\n",
    "    update_df = update_df.drop_duplicates()\n",
    "else:\n",
    "    update_df = df\n",
    "\n",
    "#df.to_csv(\"../data/cons.csv\", index=False, mode=\"a\", header=False)\n",
    "update_df.to_pickle(\"../data/df.pkl\")\n",
    "update_df.to_csv(\"../data/cons.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7be1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"data/df.pkl\")\n",
    "df = pd.read_csv(\"../data/cons.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d197fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"DataFrame shape: {df.head(5)}{df.shape}\")\n",
    "#print(df.columns)\n",
    "#print(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NET_RX which is based on cons\n",
    "#df[\"net_rx_Gbps\"] = pd.to_numeric(df[\"net_rx_Gbps\"], errors=\"coerce\")\n",
    "\n",
    "def top_n_net_rx(group):\n",
    "    n = int(group['duration'].iloc[0][1:]) #Tx = x\n",
    "    return group.sort_values('net_rx_Gbps', ascending=False).head(n)\n",
    "\n",
    "\"\"\"# sort them by the net_rx_Gbps in descending order\n",
    "df_sorted = df.sort_values(\n",
    "    [\"app\", \"proxy\", \"congestion\", \"parallel\", \"duration\", \"run\", \"net_rx_Gbps\"], \n",
    "    #[\"app\", \"date\", \"proxy\", \"congestion\", \"flow\", \"duration\", \"run\", \"net_rx_Gbps\"], \n",
    "    ascending=[True, True, True, True, True, True, False]\n",
    ")\"\"\"\n",
    "\n",
    "\"\"\"# just extract the top N rows per group (the N is the duration which the value is more than 0))\n",
    "topN_per_group = (\n",
    "    df_sorted.groupby(\n",
    "        [\"app\", \"proxy\", \"congestion\", \"parallel\", \"duration\", \"run\"], group_keys=False\n",
    "    ).apply(top_n_net_rx)\n",
    "    .reset_index(drop=True)\n",
    ")\"\"\"\n",
    "\n",
    "topN_per_group = (\n",
    "    df.groupby(\n",
    "        ['app', 'proxy', 'congestion', 'parallel', 'duration', 'run'], group_keys=False\n",
    "    ).apply(top_n_net_rx)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# add the second column (0, 1, ..., n-1) for each run\n",
    "topN_per_group['second'] = topN_per_group.groupby(\n",
    "    ['app', 'proxy', 'congestion', 'parallel', 'duration', 'run']\n",
    ").cumcount()\n",
    "\n",
    "topN_per_group = topN_per_group.sort_values(\n",
    "    ['app', 'proxy', 'congestion', 'parallel', 'duration', 'run', 'second', 'timestamp']\n",
    ")\n",
    "\n",
    "# agg by the values in each file based on run\n",
    "agg_df =(\n",
    "    topN_per_group\n",
    "    .groupby(['app', 'proxy', 'congestion', 'parallel', 'duration', 'run'])\n",
    "    .agg(\n",
    "        avg_net_rx_Gbps=('net_rx_Gbps', 'mean'),\n",
    "        avg_net_tx_Gbps=('net_tx_Gbps', 'mean'),\n",
    "        max_total_cpu=('total_cpu', 'max'),\n",
    "        mean_total_cpu=('total_cpu', 'mean'),\n",
    "        sum_disk_read_MB=('disk_read_MB', 'sum'),\n",
    "        sum_disk_write_MB=('disk_write_MB', 'sum'),\n",
    "        sum_total_rx_dropped=('total_rx_dropped', 'sum'),\n",
    "        sum_total_tx_dropped=('total_tx_dropped', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_config_df = (\n",
    "    agg_df.groupby(['app', 'proxy', 'congestion', 'parallel', 'duration'])\n",
    "    .agg(\n",
    "        mean_net_rx_Gbps=('avg_net_rx_Gbps', 'mean'),\n",
    "        mean_net_tx_Gbps=('avg_net_tx_Gbps', 'mean'),\n",
    "        max_total_cpu=('max_total_cpu', 'mean'),\n",
    "        mean_total_cpu=('mean_total_cpu', 'mean'),\n",
    "        sum_disk_read_MB=('sum_disk_read_MB', 'mean'),\n",
    "        sum_disk_write_MB=('sum_disk_write_MB', 'mean'),\n",
    "        sum_total_rx_dropped=('sum_total_rx_dropped', 'mean'),\n",
    "        sum_total_tx_dropped=('sum_total_tx_dropped', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# agg across runs for each second\n",
    "agg_per_sec = (\n",
    "    topN_per_group\n",
    "    .groupby(['app', 'proxy', 'congestion', 'parallel', 'duration', 'second'])\n",
    "    .agg(\n",
    "        mean_net_rx_Gbps=('net_rx_Gbps', 'mean'),\n",
    "        std_net_rx_Gbps=('net_rx_Gbps', 'std'),\n",
    "        count=('net_rx_Gbps', 'count'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ac4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(topN_per_group.sample(15))\n",
    "#print(topN_per_group.head(15))\n",
    "#print(f\"[INFO] TopN-per-group DataFrame shape: {topN_per_group.shape}\")\n",
    "\n",
    "#print(agg_df.head(11))  # or iloc if you want exactly the first 10\n",
    "#print(group_cols)\n",
    "#print(f\"[INFO] agg_config_df shape: {agg_df.shape}\")\n",
    "\n",
    "#print(agg_config_df.head(10))\n",
    "#print(f\"[INFO] agg_config_df shape: {agg_config_df.shape}\")\n",
    "\n",
    "#print(agg_config_df.head(10))\n",
    "#print(agg_config_df['mean_net_tx_Gbps'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c223f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = agg_df[\"app\"].unique()\n",
    "proxies = agg_df[\"proxy\"].unique()\n",
    "congestions = agg_df[\"congestion\"].unique()\n",
    "parallels = sorted(agg_df[\"parallel\"].unique(), key=lambda x: int(x[1:]))\n",
    "durations = sorted(agg_df[\"duration\"].unique(), key=lambda x: int(x[1:]))\n",
    "runs = sorted(agg_df[\"run\"].unique())\n",
    "\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "proxy_linestyles = {\n",
    "    \"Nginx\": '-',\n",
    "    \"HaproxySubprocess\": '--',\n",
    "    \"StunnelSubprocess.v1.2\": '-.',\n",
    "    \"StunnelSubprocess.v1.3\": ':'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fa34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parallels = [\"P1\", \"P3\", \"P5\"]\n",
    "#proxies = [\"HaproxySubprocess\", \"Nginx\", \"StunnelSubprocess.v1.2\", \"StunnelSubprocess.v1.3\"]\n",
    "#durations = sorted(agg_df[\"duration\"].unique(), key=lambda x: int(x[1:]))\n",
    "\n",
    "\n",
    "\n",
    "# to plot average of each run for a specific configuration\n",
    "\"\"\"\n",
    "subset = agg_df[\n",
    "    (agg_df[\"app\"] == \"iperf\") &\n",
    "    (agg_df[\"proxy\"] == \"HaproxySubprocess\") &\n",
    "    (agg_df[\"congestion\"] == \"bbr\") &\n",
    "    (agg_df[\"parallel\"] == \"P1\") &\n",
    "    (agg_df[\"duration\"] == \"T10\")\n",
    "].sort_values(\"run\")\n",
    "\n",
    "# when cols is net_rx_Gbps, use that but if avg_net_rx_Gbps, use that\n",
    "y_col = \"avg_net_rx_Gbps\" if \"avg_net_rx_Gbps\" in subset.columns else \"net_rx_Gbps\"\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(subset[\"run\"], subset[y_col], marker=\"o\")\n",
    "plt.xlabel(\"Run Number\")\n",
    "plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Throughput for 10 Runs\\n(iperf, HaproxySubprocess, bbr, P1, T10)\")\n",
    "plt.xticks(subset[\"run\"])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# to plot different times for one configuration\n",
    "\"\"\"\n",
    "parallels = [\"P1\", \"P3\", \"P5\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for par in parallels:\n",
    "    subset = agg_df[\n",
    "        (agg_df[\"app\"] == \"iperf\") &\n",
    "        (agg_df[\"proxy\"] == \"HaproxySubprocess\") &\n",
    "        (agg_df[\"congestion\"] == \"bbr\") &\n",
    "        (agg_df[\"parallel\"] == par) &\n",
    "        (agg_df[\"duration\"] == \"T10\")\n",
    "    ].sort_values(\"run\")\n",
    "    plt.plot(subset[\"run\"], subset[\"avg_net_rx_Gbps\"], marker=\"o\", label=f\"{par}\")\n",
    "\n",
    "plt.xlabel(\"Run\")\n",
    "plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Per-run Throughput for Different Parallels (T10, bbr, HaproxySubprocess, iperf)\")\n",
    "plt.legend(title=\"Parallel\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# 3 plots of per run throughput by proxy and parallel\n",
    "\"\"\"\n",
    "for par in parallels:\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    for proxy in proxies:\n",
    "        linestyle = proxy_linestyles.get(proxy, '-')\n",
    "        subset = agg_df[\n",
    "            (agg_df[\"app\"] == \"iperf\") &\n",
    "            (agg_df[\"proxy\"] == proxy) &\n",
    "            (agg_df[\"congestion\"] == \"bbr\") &\n",
    "            (agg_df[\"parallel\"] == par) &\n",
    "            (agg_df[\"duration\"] == \"T10\")\n",
    "        ].sort_values(\"run\")\n",
    "        if not subset.empty:\n",
    "            plt.plot(\n",
    "                subset[\"run\"],\n",
    "                subset[\"avg_net_rx_Gbps\"],\n",
    "                linestyle=linestyle,\n",
    "                marker=\"*\",\n",
    "                label=f\"{proxy}, {par}\"\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Run\")\n",
    "    plt.ylabel(\"Avg Net RX Throughput (Gbps)\", fontsize='small')\n",
    "    plt.title(\"Per-run Throughput by Proxy and Parallel (bbr, T10, iperf)\", fontsize='small')\n",
    "    plt.legend(title=\"Config/Parallel\", fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# 3 subplots in one figure seperating by parallels \n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 9), sharex=True, gridspec_kw={'hspace': 0.3})\n",
    "for idx, par in enumerate(parallels):\n",
    "    ax = axes[idx]\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        linestyle = proxy_linestyles.get(proxy, '-')\n",
    "        subset = agg_df[\n",
    "            (agg_df[\"app\"] == \"iperf\") &\n",
    "            (agg_df[\"proxy\"] == proxy) &\n",
    "            (agg_df[\"congestion\"] == \"bbr\") &\n",
    "            (agg_df[\"parallel\"] == par) &\n",
    "            (agg_df[\"duration\"] == \"T10\")\n",
    "        ].sort_values(\"run\")\n",
    "        if not subset.empty:\n",
    "            ax.plot( subset[\"run\"], subset[\"avg_net_rx_Gbps\"], marker=\"o\", linestyle=linestyle, \n",
    "                    color=colors[i], label=proxy if idx == 0 else \"\")\n",
    "    \n",
    "    ax.set_ylabel(f\"{par} (Gbps)\")\n",
    "    #ax.set_ylim(subset[\"avg_net_rx_Gbps\"].min() - 1, subset[\"avg_net_rx_Gbps\"].max() + 1)\n",
    "    #ax.set_ylabel(f\"{par} (Gbps)\", labelpad=30, rotation=0, ha='left', va='center')\n",
    "    #ax.yaxis.set_label_position(\"right\")\n",
    "    if idx < len(parallels) - 1:\n",
    "        ax.tick_params(labelbottom=False)  # show the  x labels only for the last subplot\n",
    "\n",
    "axes[-1].set_xlabel(\"Run\")\n",
    "fig.suptitle(\"Throughput Per Run by Parallel (Discontinuous Y, Shared X)\")\n",
    "axes[0].legend(title=\"Proxy\")  # Show legend only once\n",
    "#plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# 1 plot with 3 subplots in one figure, seperating by parallels\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 9), sharex=True, gridspec_kw={'hspace': 0.3})\n",
    "for idx, par in enumerate(parallels):\n",
    "    ax = axes[idx]\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        linestyle = proxy_linestyles.get(proxy, '-')\n",
    "        subset = agg_df[\n",
    "            (agg_df[\"app\"] == \"iperf\") &\n",
    "            (agg_df[\"proxy\"] == proxy) &\n",
    "            (agg_df[\"congestion\"] == \"bbr\") &\n",
    "            (agg_df[\"parallel\"] == par) &\n",
    "            (agg_df[\"duration\"] == \"T10\")\n",
    "        ].sort_values(\"run\")\n",
    "        if not subset.empty:\n",
    "            ax.plot(\n",
    "                subset[\"run\"], subset[\"avg_net_rx_Gbps\"],\n",
    "                marker=\"o\", linestyle=linestyle,\n",
    "                color=colors[i], label=proxy if idx == 0 else \"\"\n",
    "            )\n",
    "\n",
    "    # y-axis label to the right\n",
    "    ax.set_ylabel(f\"{par} (Gbps)\", labelpad=35)\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.5),\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    if idx < len(parallels) - 1:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "\n",
    "axes[-1].set_xlabel(\"Run\")\n",
    "fig.suptitle(\"Throughput Per Run by Parallel (Discontinuous Y, Shared X)\", y=1.04)\n",
    "\n",
    "# break marks // between subplots\n",
    "d = .03  # size of break mark\n",
    "for i in range(len(parallels) - 1):\n",
    "    kwargs = dict(transform=axes[i].transAxes, color='k', clip_on=False)\n",
    "    axes[i].plot([-d, +d], [-d, +d], **kwargs)                                      # bottom left\n",
    "    axes[i].plot([1 - d, 1 + d], [-d, +d], **kwargs)                                # bottom right\n",
    "    kwargs2 = dict(transform=axes[i + 1].transAxes, color='k', clip_on=False)\n",
    "    axes[i + 1].plot([-d, +d], [1 - d, 1 + d], **kwargs2)                           # top left\n",
    "    axes[i + 1].plot([1 - d, 1 + d], [1 - d, 1 + d], **kwargs2)                     # top right\n",
    "\n",
    "# legend outside the plot\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title=\"Proxy\", loc='center left', bbox_to_anchor=(1.01, 0.5))\n",
    "\n",
    "#plt.tight_layout(rect=[0, 0, 0.87, 1])\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# all the plots  seperating by parallels and durations showing the relevant fluctuations using //\n",
    "\"\"\"\n",
    "for dur in durations:\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 9), sharex=True, gridspec_kw={'hspace': 0.3})\n",
    "\n",
    "    for idx, par in enumerate(parallels):\n",
    "        ax = axes[idx]\n",
    "        for i, proxy in enumerate(proxies):\n",
    "            linestyle = proxy_linestyles.get(proxy, '-')\n",
    "            subset = agg_df[\n",
    "                (agg_df[\"app\"] == \"iperf\") &\n",
    "                (agg_df[\"proxy\"] == proxy) &\n",
    "                (agg_df[\"congestion\"] == \"bbr\") &\n",
    "                (agg_df[\"parallel\"] == par) &\n",
    "                (agg_df[\"duration\"] == dur)\n",
    "            ].sort_values(\"run\")\n",
    "            if not subset.empty:\n",
    "                ax.plot(\n",
    "                    subset[\"run\"], subset[\"avg_net_rx_Gbps\"],\n",
    "                    marker=\"o\", linestyle=linestyle,\n",
    "                    color=colors[i], label=proxy if idx == 0 else \"\"\n",
    "                )\n",
    "        ax.set_ylabel(f\"{par} (Gbps)\", labelpad=10)\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "        ax.yaxis.set_label_position(\"right\")\n",
    "        if idx < len(parallels) - 1:\n",
    "            ax.tick_params(labelbottom=False)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Run\")\n",
    "    fig.suptitle(f\"Throughput Per Run by Parallel (Discontinuous Y, Shared X) | Duration: {dur}\", y=.92)\n",
    "\n",
    "    # break marks // between subplots\n",
    "    d = .03\n",
    "    for i in range(len(parallels) - 1):\n",
    "        kwargs = dict(transform=axes[i].transAxes, color='k', clip_on=False)\n",
    "        axes[i].plot([-d, +d], [-d, +d], **kwargs)                                      # bottom left\n",
    "        axes[i].plot([1 - d, 1 + d], [-d, +d], **kwargs)                                # bottom right\n",
    "        kwargs2 = dict(transform=axes[i + 1].transAxes, color='k', clip_on=False)\n",
    "        axes[i + 1].plot([-d, +d], [1 - d, 1 + d], **kwargs2)                           # top left\n",
    "        axes[i + 1].plot([1 - d, 1 + d], [1 - d, 1 + d], **kwargs2)                     # top right\n",
    "\n",
    "    # legend outside the plot\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, title=\"Proxy\", loc='center left', bbox_to_anchor=(1.01, 0.5))\n",
    "\n",
    "    #plt.tight_layout(rect=[0, 0, 0.87, 1])\n",
    "    plt.show()\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 plots run based plots for throughput of different configs\n",
    "for app in apps:\n",
    "    for congestion in congestions:\n",
    "        nrows = len(parallels)\n",
    "        ncols = len(durations)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols, 3 * nrows), sharex=True)\n",
    "        # if only one duration then axes will be 1D, so make it 2D for easier indexing\n",
    "        if ncols == 1:\n",
    "            axes = axes[:, np.newaxis]\n",
    "        if nrows == 1:\n",
    "            axes = axes[np.newaxis, :]\n",
    "\n",
    "        for row_idx, par in enumerate(parallels):\n",
    "            for col_idx, dur in enumerate(durations):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                for i, proxy in enumerate(proxies):\n",
    "                    linestyle = proxy_linestyles.get(proxy, '-')\n",
    "                    subset = agg_df[\n",
    "                        (agg_df[\"app\"] == app) &\n",
    "                        (agg_df[\"proxy\"] == proxy) &\n",
    "                        (agg_df[\"congestion\"] == congestion) &\n",
    "                        (agg_df[\"parallel\"] == par) &\n",
    "                        (agg_df[\"duration\"] == dur)\n",
    "                    ].sort_values(\"run\")\n",
    "                    if not subset.empty:\n",
    "                        ax.plot(\n",
    "                            subset[\"run\"], subset[\"avg_net_rx_Gbps\"],\n",
    "                            marker=\"o\", linestyle=linestyle,\n",
    "                            color=colors[i], label=proxy if (row_idx == 0 and col_idx == 0) else \"\"\n",
    "                        )\n",
    "                ax.set_ylim(bottom=0)\n",
    "                # titles and labels\n",
    "                if row_idx == 0:\n",
    "                    ax.set_title(f\"Duration: {dur}\", fontsize=14)\n",
    "                if col_idx == 3:\n",
    "                    ax.set_ylabel(f\"{par} (Gbps)\", labelpad=10)\n",
    "                ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "                ax.yaxis.set_label_position(\"right\")\n",
    "                if row_idx < len(parallels) - 1:\n",
    "                    ax.tick_params(labelbottom=False)\n",
    "                if row_idx == len(parallels) - 1:\n",
    "                    ax.set_xlabel(\"Run\")\n",
    "\n",
    "        #legend outside the first subplot\n",
    "        handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, title=f\"{congestion.upper()} - {app.upper()}\", loc='center left', bbox_to_anchor=(.90, 0.5))\n",
    "        fig.suptitle(\"Throughput: Run | Parallel & Duration\", y=1.04, fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 0.87, 1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = df.copy()\n",
    "df = df.sort_values([\"app\", \"proxy\", \"congestion\", \"parallel\", \"duration\", \"run\"]) \n",
    "\n",
    "\n",
    "\n",
    "def top_n_net_rx(group):\n",
    "    n = int(group['duration'].iloc[0][1:])  # e.g., \"T10\" -> 10\n",
    "    return group.sort_values('net_rx_Gbps', ascending=False).head(n)\n",
    "\n",
    "topN_per_group = (\n",
    "    df.groupby(['app', 'proxy', 'congestion', 'parallel', 'duration', 'run'], group_keys=False)\n",
    "      .apply(top_n_net_rx)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2. Add the second column (0, 1, ..., n-1) for each run\n",
    "topN_per_group['second'] = topN_per_group.groupby(\n",
    "    ['app', 'proxy', 'congestion', 'parallel', 'duration', 'run']\n",
    ").cumcount()\n",
    "\n",
    "# 3. Aggregate across runs for each second\n",
    "group_cols = ['app', 'proxy', 'congestion', 'parallel', 'duration', 'second']\n",
    "agg_per_sec = (\n",
    "    topN_per_group\n",
    "    .groupby(group_cols)\n",
    "    .agg(\n",
    "        mean_net_rx_Gbps=('net_rx_Gbps', 'mean'),\n",
    "        std_net_rx_Gbps=('net_rx_Gbps', 'std'),\n",
    "        count=('net_rx_Gbps', 'count'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\"\"\"\n",
    "\n",
    "\n",
    "for app in apps:\n",
    "    for congestion in congestions:\n",
    "        nrows = len(parallels)\n",
    "        ncols = len(durations)\n",
    "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols, 3 * nrows))\n",
    "        if ncols == 1:\n",
    "            axes = axes[:, np.newaxis]\n",
    "        if nrows == 1:\n",
    "            axes = axes[np.newaxis, :]\n",
    "\n",
    "        for row_idx, par in enumerate(parallels):\n",
    "            for col_idx, dur in enumerate(durations):\n",
    "                ax = axes[row_idx, col_idx]\n",
    "                for i, proxy in enumerate(proxies):\n",
    "                    linestyle = proxy_linestyles.get(proxy, '-')\n",
    "                    color = colors[i]\n",
    "                    subset = agg_per_sec[\n",
    "                        (agg_per_sec[\"app\"] == app) &\n",
    "                        (agg_per_sec[\"proxy\"] == proxy) &\n",
    "                        (agg_per_sec[\"congestion\"] == congestion) &\n",
    "                        (agg_per_sec[\"parallel\"] == par) &\n",
    "                        (agg_per_sec[\"duration\"] == dur)\n",
    "                    ].sort_values(\"second\")\n",
    "                    # Only plot up to n seconds (duration)\n",
    "                    n = int(str(dur)[1:])\n",
    "                    subset = subset[subset[\"second\"] < n]\n",
    "                    if subset.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    x = subset[\"second\"]\n",
    "                    y = subset[\"mean_net_rx_Gbps\"]\n",
    "                    #std = subset[\"std_net_rx_Gbps\"]\n",
    "                    #ax.plot(x, y, marker=\"o\", linestyle=linestyle, color=color, label=proxy if (row_idx == 0 and col_idx == 0) else \"\")\n",
    "                    if not subset.empty:\n",
    "                        ax.plot(\n",
    "                            subset[\"second\"], subset[\"mean_net_rx_Gbps\"],\n",
    "                            marker=\"+\", linestyle=linestyle,\n",
    "                            color=colors[i], label=proxy if (row_idx == 0 and col_idx == 0) else \"\"\n",
    "                        )\n",
    "                    \n",
    "                    # add std band\n",
    "                    #ax.fill_between(x, y - std, y + std, color=color, alpha=0.15)\n",
    "                \n",
    "                ax.set_xlim(left=0, right=n-1)\n",
    "                ax.set_ylim(bottom=0)\n",
    "                if row_idx == 0:\n",
    "                    ax.set_title(f\"Duration: {dur}\", fontsize=14)\n",
    "                if col_idx == 3:\n",
    "                    ax.set_ylabel(f\"{par} (Gbps)\", labelpad=10)\n",
    "                ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "                ax.yaxis.set_label_position(\"right\")\n",
    "                if row_idx < len(parallels) - 1:\n",
    "                    ax.tick_params(labelbottom=False)\n",
    "                if row_idx == len(parallels) - 1:\n",
    "                    ax.set_xlabel(\"Second\")\n",
    "\n",
    "        handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, title=f\"{congestion.upper()} - {app.upper()}\", loc='center left', bbox_to_anchor=(.90, 0.5))\n",
    "        fig.suptitle(\"Mean Throughput per Second: Parallel & Duration\", y=1.04, fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 0.87, 1])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"second\" not in df.columns:\n",
    "    df[\"second\"] = df.groupby(['app', 'proxy', 'congestion', 'parallel', 'duration', 'run']).cumcount()\n",
    "#durations = sorted(df[\"duration\"].unique(), key=lambda x: int(x[1:])) \n",
    "\n",
    "for dur in durations:\n",
    "    # filter for one app, congestion, duration\n",
    "    facet_df = df[\n",
    "        (df[\"app\"] == \"iperf\") &\n",
    "        (df[\"congestion\"] == \"bbr\") &\n",
    "        (df[\"duration\"] == dur)\n",
    "    ].copy()\n",
    "\n",
    "    # mean throughput per config per second\n",
    "    facet_df_avg = (\n",
    "        facet_df\n",
    "        .groupby(['proxy', 'parallel', 'second'], as_index=False)[\"net_rx_Gbps\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # rows = parallel, cols = proxy\n",
    "    g = sns.FacetGrid(\n",
    "        facet_df_avg, row=\"parallel\", col=\"proxy\", \n",
    "        margin_titles=True, height=3, aspect=2\n",
    "    )\n",
    "    for ax in g.axes.flat:\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "    g.map_dataframe(sns.lineplot, x=\"second\", y=\"net_rx_Gbps\", color='red')\n",
    "    g.set_axis_labels(\"Second\", \"Avg Net RX Throughput (Gbps)\")\n",
    "    g.fig.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(f\"Per-Second Avg Throughput by Parallel and Proxy\\n(app=iperf, congestion=bbr, duration={dur})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets:  deep, muted, bright, pastel, dark, colorblind, husl, Set1, Set2, Set3, sns.color_palette(\"ch:s=-.2,r=.6\", as_cmap=True)\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    agg_config_df, row=\"app\", col=\"proxy\", hue=\"congestion\", \n",
    "    margin_titles=True, height=4, palette=\"husl\"\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "g.map(sns.barplot, \"parallel\", \"mean_net_rx_Gbps\", order=sorted(agg_config_df[\"parallel\"].unique()), alpha=0.6, errorbar=None)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dur in durations:\n",
    "    subset = agg_config_df[agg_config_df[\"duration\"] == dur]\n",
    "    g = sns.FacetGrid(\n",
    "        subset, \n",
    "        row=\"app\", col=\"proxy\", hue=\"congestion\",\n",
    "        margin_titles=True, height=4, palette=\"Set1\"\n",
    "    )\n",
    "    for ax in g.axes.flat:\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "    g.map(sns.barplot, \"parallel\", \"mean_net_tx_Gbps\", order=sorted(subset[\"parallel\"].unique()), alpha=0.6)\n",
    "    g.add_legend()\n",
    "    plt.suptitle(f\"Duration: {dur}\", y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dur in durations:\n",
    "    subset = agg_config_df[agg_config_df[\"duration\"] == dur]\n",
    "    g = sns.FacetGrid(\n",
    "        subset, \n",
    "        row=\"app\", col=\"proxy\", hue=\"congestion\",\n",
    "        margin_titles=True, height=4\n",
    "    )\n",
    "    g.map(sns.barplot, \"parallel\", \"mean_total_cpu\", order=sorted(subset[\"parallel\"].unique()), alpha=0.6)\n",
    "    g.add_legend()\n",
    "    g.set_axis_labels(\"Parallel Streams\", \"Mean Total CPU (%)\")\n",
    "    g.fig.suptitle(f\"Mean Total CPU Usage (Duration: {dur})\", y=1.03)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    agg_config_df, \n",
    "    row=\"app\", col=\"proxy\", hue=\"congestion\", \n",
    "    margin_titles=True, height=4\n",
    ")\n",
    "g.map(\n",
    "    sns.barplot,\n",
    "    \"parallel\", \"mean_total_cpu\",\n",
    "    order=sorted(agg_config_df[\"parallel\"].unique()),\n",
    "    alpha=0.6\n",
    ")\n",
    "g.add_legend()\n",
    "g.set_axis_labels(\"Parallel Streams\", \"Mean Total CPU (%)\")\n",
    "g.fig.suptitle(\"Mean Total CPU Usage by Parallel, App, Proxy, Congestion\", y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d518acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = sorted(agg_config_df[\"duration\"].unique(), key=lambda x: int(x[1:]))\n",
    "\n",
    "for dur in durations:\n",
    "    subset = agg_config_df[agg_config_df[\"duration\"] == dur]\n",
    "    g = sns.FacetGrid(subset, row=\"app\", col=\"proxy\", hue=\"congestion\", margin_titles=True, height=4, aspect=1)\n",
    "    g.map(sns.barplot, \"parallel\", \"mean_total_cpu\", order=sorted(subset[\"parallel\"].unique()), alpha=0.6)\n",
    "    \n",
    "    g.add_legend()\n",
    "    g.set_axis_labels(\"Parallel Streams\", \"Mean Total CPU (%)\")\n",
    "    g.fig.suptitle(f\"Mean Total CPU Usage by Parallel, App, Proxy, Congestion\\nDuration: {dur}\", y=1.06)\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    agg_config_df,\n",
    "    row=\"congestion\", col=\"proxy\", hue=\"app\",\n",
    "    margin_titles=True, height=4\n",
    ")\n",
    "g.map(sns.barplot, \"parallel\", \"mean_net_tx_Gbps\", order=sorted(agg_config_df[\"parallel\"].unique()), alpha=0.6)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    agg_config_df,\n",
    "    row=\"app\", col=\"congestion\", hue=\"proxy\",\n",
    "    margin_titles=True, height=3\n",
    ")\n",
    "g.map(sns.barplot, \"parallel\", \"mean_net_tx_Gbps\", order=sorted(agg_config_df[\"parallel\"].unique()), alpha=0.6)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "g = sns.FacetGrid(\n",
    "    agg_config_df,\n",
    "    row=\"app\", col=\"duration\", hue=\"proxy\",\n",
    "    margin_titles=True, height=4\n",
    ")\n",
    "g.map(sns.barplot, \"parallel\", \"mean_net_tx_Gbps\", order=sorted(agg_config_df[\"parallel\"].unique()), alpha=0.6)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a28e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    agg_config_df,\n",
    "    row=\"app\", col=\"proxy\", hue=\"parallel\",\n",
    "    margin_titles=True, height=4, palette=\"husl\"\n",
    ")\n",
    "g.map(sns.barplot, \"duration\", \"mean_net_tx_Gbps\", order=sorted(agg_config_df[\"duration\"].unique()), alpha=0.4)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee43b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "configs_to_plot = [\n",
    "    (\"HaproxySubprocess\", \"bbr\"),\n",
    "    (\"HaproxySubprocess\", \"cubic\"),\n",
    "    (\"StunnelSubprocess.tls.v1.2\", \"bbr\"),\n",
    "    (\"StunnelSubprocess.tls.v1.2\", \"cubic\"),\n",
    "    (\"StunnelSubprocess.tls.v1.3\", \"bbr\"),   \n",
    "    (\"StunnelSubprocess.tls.v1.3\", \"cubic\"),  \n",
    "]\n",
    "\n",
    "labels = []\n",
    "avg_rx = []\n",
    "\n",
    "for proxy, congestion in configs_to_plot:\n",
    "    # str.startswith or strip() \n",
    "    subset = agg_config_df[\n",
    "        (agg_config_df[\"proxy\"] == proxy) &\n",
    "        (agg_config_df[\"congestion\"] == congestion)\n",
    "    ]\n",
    "    if not subset.empty:\n",
    "        avg_value = subset[\"mean_net_tx_Gbps\"].mean()\n",
    "        avg_rx.append(avg_value)\n",
    "    else:\n",
    "        avg_rx.append(0)\n",
    "    labels.append(f\"{proxy}\\n{congestion}\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bars = plt.bar(labels, avg_rx)\n",
    "plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Avg Net RX Throughput by Proxy & Congestion\")\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "#plt.tight_layout()\n",
    "#plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab934560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "agg_df[\"run\"] = pd.to_numeric(agg_df[\"run\"], errors=\"coerce\")\n",
    "\n",
    "example_config = {\n",
    "    \"app\": \"iperf\",\n",
    "    \"proxy\": \"HaproxySubprocess\",\n",
    "    \"congestion\": \"bbr\",\n",
    "    \"parallel\": \"P1\",\n",
    "    \"duration\": \"T10\"\n",
    "}\n",
    "\n",
    "mask = (\n",
    "    (agg_df[\"app\"] == example_config[\"app\"]) &\n",
    "    (agg_df[\"proxy\"] == example_config[\"proxy\"]) &\n",
    "    (agg_df[\"congestion\"] == example_config[\"congestion\"]) &\n",
    "    (agg_df[\"parallel\"] == example_config[\"parallel\"]) &\n",
    "    (agg_df[\"duration\"] == example_config[\"duration\"])\n",
    ")\n",
    "\n",
    "per_run = (\n",
    "    agg_df[mask]\n",
    "    .groupby(\"run\")[\"avg_net_rx_Gbps\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"run\")\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(per_run[\"run\"], per_run[\"avg_net_rx_Gbps\"], marker='o', linestyle='-')\n",
    "plt.xlabel(\"Run Number\")\n",
    "plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Per-Run Throughput (Averaged Over TopN Per Run)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\n",
    "group_cols = [\"proxy\", \"congestion\", \"run\"]\n",
    "mean_per_run = (\n",
    "    agg_df\n",
    "    .groupby(group_cols)[\"avg_net_rx_Gbps\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"run\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for (proxy, congestion), group in mean_per_run.groupby([\"proxy\", \"congestion\"]):\n",
    "    plt.plot(\n",
    "        group[\"run\"], group[\"avg_net_rx_Gbps\"], marker='o', label=f\"{proxy} / {congestion}\"\n",
    "    )\n",
    "plt.xlabel(\"Run Number\")\n",
    "plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Throughput Across Runs (All Proxies & Congestion)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proxies = [\n",
    "    \"Nginx\",\n",
    "    \"HaproxySubprocess\",\n",
    "    \"StunnelSubprocess.v1.2\",\n",
    "    \"StunnelSubprocess.v1.3\"\n",
    "]\n",
    "congestions = [\"bbr\", \"cubic\"]\n",
    "\n",
    "groups = [\n",
    "    (\"mini-apps\", \"Nginx\"),\n",
    "    (\"mini-apps\", \"HaproxySubprocess\"),\n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.2\"),\n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.3\"),\n",
    "    (\"iperf\", \"Nginx\"),\n",
    "    (\"iperf\", \"HaproxySubprocess\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.2\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.3\"),\n",
    "]\n",
    "\n",
    "congestions = [\"bbr\", \"cubic\"]\n",
    "colors = ['tab:blue', 'tab:orange']\n",
    "\n",
    "\n",
    "bar_data = []\n",
    "for proxy in proxies:\n",
    "    vals = []\n",
    "    for congestion in congestions:\n",
    "        subset = agg_config_df[\n",
    "            (agg_config_df[\"proxy\"] == proxy) &\n",
    "            (agg_config_df[\"congestion\"] == congestion)\n",
    "        ]\n",
    "        vals.append(subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0)\n",
    "    bar_data.append(vals)\n",
    "\n",
    "bar_data = np.array(bar_data) \n",
    "\n",
    "bar_width = 0.20\n",
    "x = np.arange(len(congestions)) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "\n",
    "for i, (proxy, color) in enumerate(zip(proxies, colors)):\n",
    "    ax.bar(x + i * bar_width, bar_data[i], width=bar_width, label=proxy, color=color)\n",
    "\n",
    "ax.set_xticks(x + bar_width)\n",
    "ax.set_xticklabels(congestions)\n",
    "ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "ax.set_xlabel(\"Congestion Control\")\n",
    "ax.set_title(\"Throughput\")\n",
    "ax.legend(title=\"Proxy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"rx_bar_data = []\n",
    "tx_bar_data = []\n",
    "for proxy in proxies:\n",
    "    rx_vals, tx_vals = [], []\n",
    "    for congestion in congestions:\n",
    "        subset = agg_config_df[\n",
    "            (agg_config_df[\"proxy\"] == proxy) &\n",
    "            (agg_config_df[\"congestion\"] == congestion)\n",
    "        ]\n",
    "        rx_vals.append(subset[\"sum_total_rx_dropped\"].sum() if not subset.empty else 0)\n",
    "        tx_vals.append(subset[\"sum_total_tx_dropped\"].sum() if not subset.empty else 0)\n",
    "    rx_bar_data.append(rx_vals)\n",
    "    tx_bar_data.append(tx_vals)\n",
    "\n",
    "rx_bar_data = np.array(rx_bar_data)\n",
    "tx_bar_data = np.array(tx_bar_data)\n",
    "\n",
    "bar_width = 0.18\n",
    "x = np.arange(len(congestions))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
    "\n",
    "for i, (proxy, color) in enumerate(zip(proxies, colors)):\n",
    "    ax.bar(x + i * 2 * bar_width, rx_bar_data[i], width=bar_width, label=f\"{proxy} RX\", color=color, alpha=0.7)\n",
    "    ax.bar(x + i * 2 * bar_width + bar_width, tx_bar_data[i], width=bar_width, label=f\"{proxy} TX\", color=color, hatch='//', alpha=0.7)\n",
    "\n",
    "ax.set_xticks(x + bar_width)\n",
    "ax.set_xticklabels(congestions)\n",
    "ax.set_ylabel(\"Retransmissions (sum)\")\n",
    "ax.set_xlabel(\"Congestion Control\")\n",
    "ax.set_title(\"RX & TX (Retransmissions\")\n",
    "ax.legend(title=\"Legend\", ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806a0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define groups as tuples: (app, proxy)\n",
    "\"\"\"groups = [\n",
    "    (\"mini-apps\", \"Nginx\"),\n",
    "    (\"mini-apps\", \"HaproxySubprocess\"),\n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.2\"),\n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.3\"),\n",
    "    (\"iperf\", \"Nginx\"),\n",
    "    (\"iperf\", \"HaproxySubprocess\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.2\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.3\"),\n",
    "]\"\"\"\n",
    "groups = [\n",
    "    (\"mini-apps\", \"Nginx\"),\n",
    "    (\"iperf\", \"Nginx\"),\n",
    "    \n",
    "    (\"mini-apps\", \"HaproxySubprocess\"),\n",
    "    (\"iperf\", \"HaproxySubprocess\"),\n",
    "    \n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.2\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.2\"),\n",
    "    \n",
    "    (\"mini-apps\", \"StunnelSubprocess.v1.3\"),\n",
    "    (\"iperf\", \"StunnelSubprocess.v1.3\"),\n",
    "]\n",
    "\n",
    "congestions = [\"bbr\", \"cubic\"]\n",
    "colors = ['tab:blue', 'tab:orange']\n",
    "\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(groups))\n",
    "\n",
    "# Prepare bar heights\n",
    "bbr_vals, cubic_vals = [], []\n",
    "for app, proxy in groups:\n",
    "    for congestion in congestions:\n",
    "        subset = agg_config_df[\n",
    "            (agg_config_df[\"app\"] == app) &\n",
    "            (agg_config_df[\"proxy\"] == proxy) &\n",
    "            (agg_config_df[\"congestion\"] == congestion)\n",
    "        ]\n",
    "        value = subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0\n",
    "        if congestion == \"bbr\":\n",
    "            bbr_vals.append(value)\n",
    "        else:\n",
    "            cubic_vals.append(value)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "# Plot bars side-by-side for each group\n",
    "ax.bar(x - bar_width/2, bbr_vals, width=bar_width, color=colors[0], label='bbr')\n",
    "ax.bar(x + bar_width/2, cubic_vals, width=bar_width, color=colors[1], label='cubic')\n",
    "\n",
    "# Make x-tick labels as \"app\\nproxy\"\n",
    "xtick_labels = [f\"{app}\\n{proxy}\" for (app, proxy) in groups]\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(xtick_labels, rotation=15, ha='center')\n",
    "\n",
    "ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "ax.set_xlabel(\"Experiment Group\")\n",
    "ax.set_title(\"Throughput by App, Proxy, and Congestion Control\")\n",
    "ax.legend(title=\"Congestion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = agg_config_df[\"app\"].unique()\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = [\"bbr\", \"cubic\"]\n",
    "\n",
    "bar_values = []\n",
    "labels = []\n",
    "for proxy in proxies:\n",
    "    for congestion in congestions:\n",
    "        for app in apps:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == congestion) &\n",
    "                (agg_config_df[\"app\"] == app)\n",
    "            ]\n",
    "            value = subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0\n",
    "            bar_values.append(value)\n",
    "            labels.append(f\"{proxy}-{app}-{congestion}\")\n",
    "            \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "\n",
    "# Plot bars side-by-side for each group\n",
    "ax.bar(x - bar_width/2, bbr_vals, width=bar_width, color=colors[0], label='bbr')\n",
    "ax.bar(x + bar_width/2, cubic_vals, width=bar_width, color=colors[1], label='cubic')\n",
    "\n",
    "# Make x-tick labels as \"app\\nproxy\"\n",
    "xtick_labels = [f\"{app}\\n{proxy}\" for (app, proxy) in groups]\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(xtick_labels, rotation=15, ha='center')\n",
    "\n",
    "ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "ax.set_xlabel(\"Experiment Group\")\n",
    "ax.set_title(\"Throughput by App, Proxy, and Congestion Control\")\n",
    "ax.legend(title=\"Congestion\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "apps = [\"mini-apps\", \"iperf\"]\n",
    "congestions = [\"bbr\", \"cubic\"]\n",
    "\"\"\"proxies = [\n",
    "    \"Nginx\",\n",
    "    \"HaproxySubprocess\",\n",
    "    \"StunnelSubprocess.v1.2\",\n",
    "    \"StunnelSubprocess.v1.3\"\n",
    "]\"\"\"\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
    "\n",
    "# All group combinations\n",
    "groups = [(app, cong) for app in apps for cong in congestions]\n",
    "n_groups = len(groups)\n",
    "n_proxies = len(proxies)\n",
    "bar_width = 0.2\n",
    "x = np.arange(n_groups)  # group locations\n",
    "\n",
    "# Prepare bar heights: shape [n_proxies, n_groups]\n",
    "bar_data = np.zeros((n_proxies, n_groups))\n",
    "for group_idx, (app, cong) in enumerate(groups):\n",
    "    for proxy_idx, proxy in enumerate(proxies):\n",
    "        subset = agg_config_df[\n",
    "            (agg_config_df[\"app\"] == app) &\n",
    "            (agg_config_df[\"congestion\"] == cong) &\n",
    "            (agg_config_df[\"proxy\"] == proxy)\n",
    "        ]\n",
    "        bar_data[proxy_idx, group_idx] = subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "for proxy_idx, (proxy, color) in enumerate(zip(proxies, colors)):\n",
    "    ax.bar(\n",
    "        x + proxy_idx * bar_width,\n",
    "        bar_data[proxy_idx],\n",
    "        width=bar_width,\n",
    "        label=proxy,\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# X-tick labels: app\\ncongestion\n",
    "xtick_labels = [f\"{app}\\n{cong}\" for (app, cong) in groups]\n",
    "ax.set_xticks(x + (n_proxies-1) * bar_width / 2)\n",
    "ax.set_xticklabels(xtick_labels, rotation=0)\n",
    "\n",
    "ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "ax.set_xlabel(\"App & Congestion\")\n",
    "ax.set_title(\"Throughput: Proxy Comparison by App and Congestion\")\n",
    "ax.legend(title=\"Proxy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = sorted(agg_config_df[\"duration\"].unique(), key=lambda x: int(x[1:]))\n",
    "\n",
    "group_cols = ['app', 'proxy', 'parallel','congestion']\n",
    "groups = agg_config_df[group_cols].drop_duplicates().values.tolist()\n",
    "\n",
    "bar_data = np.zeros((len(durations), len(groups)))\n",
    "for group_idx, (app, proxy, parallel, congestion) in enumerate(groups):\n",
    "    for dur_idx, duration in enumerate(durations):\n",
    "        subset = agg_config_df[\n",
    "            (agg_config_df[\"app\"] == app) &\n",
    "            (agg_config_df[\"proxy\"] == proxy) &\n",
    "            (agg_config_df[\"parallel\"] == parallel) &\n",
    "            (agg_config_df[\"congestion\"] == congestion) &\n",
    "            (agg_config_df[\"duration\"] == duration)\n",
    "        ]\n",
    "        bar_data[dur_idx, group_idx] = subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_groups = len(groups)\n",
    "n_durations = len(durations)\n",
    "bar_width = 0.8 / n_durations   # Make bars not overflow\n",
    "x = np.arange(n_groups)\n",
    "duration_colors = plt.cm.viridis(np.linspace(0, 1, n_durations))  # or use your own color list\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for dur_idx, duration in enumerate(durations):\n",
    "    ax.bar(\n",
    "        x + dur_idx * bar_width,\n",
    "        bar_data[dur_idx],\n",
    "        width=bar_width,\n",
    "        label=duration,\n",
    "        color=duration_colors[dur_idx]\n",
    "    )\n",
    "\n",
    "\n",
    "xtick_labels = [f\"{app}\\n{proxy}\\n{parallel}\\n{congestion}\" for (app, proxy, parallel, congestion) in groups]\n",
    "ax.set_xticks(x + bar_width * (n_durations - 1) / 2)\n",
    "ax.set_xticklabels(xtick_labels, rotation=15, ha='center')\n",
    "\n",
    "ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "ax.set_xlabel(\"App, Proxy, Parallel, Congestion\")\n",
    "ax.set_title(\"Throughput by Duration, App, Proxy, Congestion\")\n",
    "ax.legend(title=\"Duration\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "durations = sorted(agg_config_df[\"duration\"].unique(), key=lambda x: int(x[1:]))\n",
    "parallels = sorted(agg_config_df[\"parallel\"].unique(), key=lambda x: int(x[1:]))\n",
    "apps = agg_config_df[\"app\"].unique()\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = agg_config_df[\"congestion\"].unique()\n",
    "\n",
    "proxy_colors = dict(zip(proxies, plt.cm.tab10.colors)) \n",
    "\n",
    "for duration in durations:\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    x = np.arange(len(congestions))\n",
    "    bar_width = 0.15\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        heights = []\n",
    "        for congestion in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == congestion) &\n",
    "                (agg_config_df[\"duration\"] == duration)\n",
    "            ]\n",
    "            heights.append(subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0)\n",
    "        ax.bar(x + i*bar_width, heights, width=bar_width, label=proxy, color=proxy_colors[proxy])\n",
    "    ax.set_xticks(x + bar_width * (len(proxies)-1)/2)\n",
    "    ax.set_xticklabels(congestions)\n",
    "    ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "    ax.set_title(f\"Throughput by Proxy and Congestion ({duration})\")\n",
    "    ax.legend(title=\"Proxy\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d211390",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallels = sorted(agg_config_df[\"parallel\"].unique(), key=lambda x: int(x[1:]))\n",
    "apps = agg_config_df[\"app\"].unique()\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = agg_config_df[\"congestion\"].unique()\n",
    "\n",
    "for parallel in parallels:\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    x = np.arange(len(congestions))\n",
    "    bar_width = 0.15\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        heights = []\n",
    "        for congestion in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == congestion) &\n",
    "                (agg_config_df[\"parallel\"] == parallel)\n",
    "            ]\n",
    "            heights.append(subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0)\n",
    "        ax.bar(x + i*bar_width, heights, width=bar_width, label=proxy, color=proxy_colors[proxy])\n",
    "    ax.set_xticks(x + bar_width * (len(proxies)-1)/2)\n",
    "    ax.set_xticklabels(congestions)\n",
    "    ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "    ax.set_title(f\"Throughput by Proxy and Congestion (Parallel {parallel})\")\n",
    "    ax.legend(title=\"Proxy\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_colors = dict(zip(durations, plt.cm.viridis(np.linspace(0,1,len(durations)))))\n",
    "\n",
    "for proxy in proxies:\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    x = np.arange(len(congestions))\n",
    "    bar_width = 0.15\n",
    "    for i, duration in enumerate(durations):\n",
    "        heights = []\n",
    "        for congestion in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == congestion) &\n",
    "                (agg_config_df[\"duration\"] == duration)\n",
    "            ]\n",
    "            heights.append(subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0)\n",
    "        ax.bar(x + i*bar_width, heights, width=bar_width, label=duration, color=duration_colors[duration])\n",
    "    ax.set_xticks(x + bar_width * (len(durations)-1)/2)\n",
    "    ax.set_xticklabels(congestions)\n",
    "    ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "    ax.set_title(f\"Throughput by Duration and Congestion ({proxy})\")\n",
    "    ax.legend(title=\"Duration\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501dbd4",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "apps = agg_config_df[\"app\"].unique()\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = agg_config_df[\"congestion\"].unique()\n",
    "\n",
    "for app in apps:\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    bar_width = 0.2\n",
    "    x = np.arange(len(congestions))\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        vals = []\n",
    "        for cong in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"app\"] == app) &\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == cong)\n",
    "            ]\n",
    "            vals.append(subset[\"mean_net_tx_Gbps\"].mean() if not subset.empty else 0)\n",
    "        ax.bar(x + i*bar_width, vals, width=bar_width, label=proxy)\n",
    "    ax.set_xticks(x + bar_width*(len(proxies)-1)/2)\n",
    "    ax.set_xticklabels(congestions)\n",
    "    ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "    ax.set_title(f\"Throughput by Proxy & Congestion ({app})\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3957e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for app in apps:\n",
    "    for proxy in proxies:\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        for cong in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"app\"] == app) &\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == cong)\n",
    "            ]\n",
    "            if not subset.empty:\n",
    "                ax.plot(\n",
    "                    subset[\"parallel\"], subset[\"mean_net_tx_Gbps\"], \n",
    "                    marker='o', label=f\"{cong}\"\n",
    "                )\n",
    "        ax.set_xlabel(\"Parallel Streams\")\n",
    "        ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "        ax.set_title(f\"Throughput by Parallel Streams ({app}, {proxy})\")\n",
    "        ax.legend(title=\"Congestion\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "\n",
    "apps = agg_config_df[\"app\"].unique()\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = agg_config_df[\"congestion\"].unique()\n",
    "\n",
    "# different line style to each proxy\n",
    "proxy_linestyles = {\n",
    "    \"Nginx\": '-',\n",
    "    \"HaproxySubprocess\": '--',\n",
    "    \"StunnelSubprocess.v1.2\": '-.',\n",
    "    \"StunnelSubprocess.v1.3\": ':'\n",
    "}\n",
    "\n",
    "for app in apps:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for proxy in proxies:\n",
    "        linestyle = proxy_linestyles.get(proxy, '-')\n",
    "        for cong in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"app\"] == app) &\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == cong)\n",
    "            ].sort_values(\"parallel\")\n",
    "            if not subset.empty:\n",
    "                ax.plot(\n",
    "                    subset[\"parallel\"], subset[\"mean_net_tx_Gbps\"],\n",
    "                    marker='o',\n",
    "                    linestyle=linestyle,\n",
    "                    label=f\"{proxy} - {cong}\"\n",
    "                )\n",
    "    ax.set_xlabel(\"Parallel Streams\")\n",
    "    ax.set_ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "    ax.set_title(f\"Throughput by Parallel Streams ({app})\")\n",
    "    ax.legend(title=\"Proxy / Congestion\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e219ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for app in apps:\n",
    "    for proxy in proxies:\n",
    "        for cong in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"app\"] == app) &\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == cong)\n",
    "            ]\n",
    "            if not subset.empty:\n",
    "                plt.figure(figsize=(8,4))\n",
    "                plt.plot(\n",
    "                    subset[\"duration\"].apply(lambda x: int(x[1:])), \n",
    "                    subset[\"mean_net_tx_Gbps\"], marker='o'\n",
    "                )\n",
    "                plt.xlabel(\"Duration (seconds)\")\n",
    "                plt.ylabel(\"Avg Net RX Throughput (Gbps)\")\n",
    "                plt.title(f\"Throughput vs Duration ({app}, {proxy}, {cong})\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4314f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for app in apps:\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    bar_width = 0.2\n",
    "    x = np.arange(len(congestions))\n",
    "    for i, proxy in enumerate(proxies):\n",
    "        vals = []\n",
    "        for cong in congestions:\n",
    "            subset = agg_config_df[\n",
    "                (agg_config_df[\"app\"] == app) &\n",
    "                (agg_config_df[\"proxy\"] == proxy) &\n",
    "                (agg_config_df[\"congestion\"] == cong)\n",
    "            ]\n",
    "            vals.append(subset[\"sum_total_rx_dropped\"].sum() if not subset.empty else 0)\n",
    "        ax.bar(x + i*bar_width, vals, width=bar_width, label=proxy)\n",
    "    ax.set_xticks(x + bar_width*(len(proxies)-1)/2)\n",
    "    ax.set_xticklabels(congestions)\n",
    "    ax.set_ylabel(\"Total RX Retransmissions\")\n",
    "    ax.set_title(f\"Retransmissions by Proxy & Congestion ({app})\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63076645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(\n",
    "    data=df, \n",
    "    x=\"proxy\", \n",
    "    y=\"net_rx_Gbps\", \n",
    "    hue=\"congestion\"\n",
    ")\n",
    "plt.title(\"Run-to-Run Throughput Variability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddcdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(\n",
    "    data=df, \n",
    "    x=\"proxy\", \n",
    "    y=\"total_rx_dropped\", \n",
    "    hue=\"congestion\"\n",
    ")\n",
    "plt.title(\"Run-to-Run Retransmission Variability\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"run_subset = df[\n",
    "    (df[\"app\"] == \"mini-apps\") & \n",
    "    (df[\"proxy\"] == \"Nginx\") & \n",
    "    (df[\"congestion\"] == \"bbr\") &\n",
    "    (df[\"run\"] == 10)\n",
    "]\n",
    "plt.plot(run_subset[\"timestamp\"], run_subset[\"net_rx_Gbps\"])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Net RX Throughput (Gbps)\")\n",
    "plt.title(\"Throughput Over Time (Example Run)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# (Optional) Sort or filter your DataFrame as needed\n",
    "# agg_config_df = agg_config_df[agg_config_df[\"app\"] == \"mini-apps\"] # example\n",
    "\n",
    "# Create a column with combined label for faceting (optional, or use row/col separately)\n",
    "agg_config_df[\"facet\"] = agg_config_df[\"proxy\"] + \"\\n\" + agg_config_df[\"congestion\"]\n",
    "\n",
    "# Get all unique proxies and congestions for faceting\n",
    "proxies = agg_config_df[\"proxy\"].unique()\n",
    "congestions = agg_config_df[\"congestion\"].unique()\n",
    "\n",
    "# Set up the FacetGrid\n",
    "g = sns.FacetGrid(\n",
    "    agg_config_df,\n",
    "    row=\"proxy\", col=\"congestion\",\n",
    "    margin_titles=True, height=3,\n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "# Define a function to draw a heatmap on each facet\n",
    "def draw_heatmap(data, **kwargs):\n",
    "    pivot = data.pivot_table(\n",
    "        index=\"parallel\", columns=\"duration\", values=\"mean_net_tx_Gbps\", aggfunc=\"mean\"\n",
    "    )\n",
    "    sns.heatmap(\n",
    "        pivot,\n",
    "        annot=True, fmt=\".2f\", cmap=\"viridis\",\n",
    "        cbar=False,  # Only add colorbar to one facet for clarity\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "# Map the function onto the FacetGrid\n",
    "g.map_dataframe(draw_heatmap)\n",
    "\n",
    "# Set overall title and axis labels\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle(\"Throughput by Parallel, Duration (Faceted by Proxy and Congestion)\")\n",
    "g.set_axis_labels(\"Duration\", \"Parallel Streams\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ace5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = (\n",
    "    agg_config_df\n",
    "    .groupby(['app', 'proxy', 'congestion'])\n",
    "    .agg(max_rx=('mean_net_tx_Gbps', 'max'))\n",
    "    .reset_index()\n",
    ")\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=best_df, \n",
    "    x=\"proxy\", y=\"max_rx\", hue=\"congestion\"\n",
    ")\n",
    "plt.title(\"Best Throughput per App, Proxy, Congestion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    agg_config_df\n",
    "    .groupby(['app', 'proxy', 'congestion'])\n",
    "    .agg(\n",
    "        mean_rx=('mean_net_tx_Gbps', 'mean'),\n",
    "        mean_retrans=('sum_total_rx_dropped', 'mean'),\n",
    "        max_cpu=('max_total_cpu', 'max')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517cc59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "651ce64d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18fd2832",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ea20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596e0ffe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".chi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
